{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordfreq import top_n_list, word_frequency\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from wiki_controller import WikiController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e810787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_words(language):\n",
    "    return top_n_list(language, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc76dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = WikiController(\"https://bulbapedia.bulbagarden.net/wiki\")\n",
    "\n",
    "def get_wiki_counts(phrase):\n",
    "    controller.scrapper.scrape(phrase=phrase)\n",
    "    text = controller.scrapper.get_words().lower()\n",
    "    words = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text) \n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "long_wiki_phrase = \"History of Pokémon\"\n",
    "long_wiki_counts = get_wiki_counts(long_wiki_phrase)\n",
    "\n",
    "bad_wiki_phrase = \"List of Japanese Pokémon names\" \n",
    "bad_wiki_counts = get_wiki_counts(bad_wiki_phrase)\n",
    "\n",
    "eng_lang_top = get_topk_words(\"en\")\n",
    "pl_lang_top = get_topk_words(\"pl\")\n",
    "esp_lang_top = get_topk_words(\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5fa386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_confidence_score(word_counts, top_k_language):\n",
    "    lang_set = {word for word in top_k_language}\n",
    "    \n",
    "    total_tokens = sum(word_counts.values())\n",
    "    \n",
    "    matched_tokens = 0\n",
    "    for word, count in word_counts.items():\n",
    "        if word in lang_set:\n",
    "            matched_tokens += count\n",
    "            \n",
    "    return matched_tokens / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375076d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_counts(text):\n",
    "    words = re.findall(r\"\\b[a-z]+(?:'[a-z]+)?\\b\", text) \n",
    "    return Counter(words)\n",
    "\n",
    "with open(\"kubus_puchatek_EN.txt\", \"r\") as f:\n",
    "    en_text = f.read()\n",
    "\n",
    "with open(\"kubus_puchatek_PL.txt\", \"r\") as f:\n",
    "    pl_text = f.read()\n",
    "\n",
    "with open(\"Fingir_y_amar.txt\", \"r\") as f:\n",
    "    es_text = f.read()\n",
    "\n",
    "en_text_count = get_language_counts(en_text)\n",
    "pl_text_count = get_language_counts(pl_text)\n",
    "es_text_count = get_language_counts(es_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd09e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k       Text Language     Score\n",
      "0      3  Wiki Long       en  0.133255\n",
      "1      3  Wiki Long       pl  0.001177\n",
      "2      3  Wiki Long       es  0.000000\n",
      "3      3   Wiki Bad       en  0.011147\n",
      "4      3   Wiki Bad       pl  0.002447\n",
      "5      3   Wiki Bad       es  0.000272\n",
      "6      3    Text en       en  0.119044\n",
      "7      3    Text en       pl  0.000000\n",
      "8      3    Text en       es  0.002713\n",
      "9      3    Text pl       en  0.034666\n",
      "10     3    Text pl       pl  0.130527\n",
      "11     3    Text pl       es  0.006721\n",
      "12     3    Text es       en  0.000000\n",
      "13     3    Text es       pl  0.000000\n",
      "14     3    Text es       es  0.156561\n",
      "15    10  Wiki Long       en  0.235917\n",
      "16    10  Wiki Long       pl  0.023386\n",
      "17    10  Wiki Long       es  0.024710\n",
      "18    10   Wiki Bad       en  0.028548\n",
      "19    10   Wiki Bad       pl  0.005438\n",
      "20    10   Wiki Bad       es  0.002719\n",
      "21    10    Text en       en  0.219603\n",
      "22    10    Text en       pl  0.033407\n",
      "23    10    Text en       es  0.036629\n",
      "24    10    Text pl       en  0.120269\n",
      "25    10    Text pl       pl  0.260347\n",
      "26    10    Text pl       es  0.027945\n",
      "27    10    Text es       en  0.049774\n",
      "28    10    Text es       pl  0.000000\n",
      "29    10    Text es       es  0.317647\n",
      "30   100  Wiki Long       en  0.421385\n",
      "31   100  Wiki Long       pl  0.081630\n",
      "32   100  Wiki Long       es  0.025004\n",
      "33   100   Wiki Bad       en  0.059271\n",
      "34   100   Wiki Bad       pl  0.013322\n",
      "35   100   Wiki Bad       es  0.004078\n",
      "36   100    Text en       en  0.565881\n",
      "37   100    Text en       pl  0.078684\n",
      "38   100    Text en       es  0.039172\n",
      "39   100    Text pl       en  0.153520\n",
      "40   100    Text pl       pl  0.556774\n",
      "41   100    Text pl       es  0.053414\n",
      "42   100    Text es       en  0.057919\n",
      "43   100    Text es       pl  0.057919\n",
      "44   100    Text es       es  0.568326\n",
      "45  1000  Wiki Long       en  0.680688\n",
      "46  1000  Wiki Long       pl  0.294602\n",
      "47  1000  Wiki Long       es  0.214885\n",
      "48  1000   Wiki Bad       en  0.104676\n",
      "49  1000   Wiki Bad       pl  0.051115\n",
      "50  1000   Wiki Bad       es  0.038608\n",
      "51  1000    Text en       en  0.813973\n",
      "52  1000    Text en       pl  0.268781\n",
      "53  1000    Text en       es  0.212311\n",
      "54  1000    Text pl       en  0.238415\n",
      "55  1000    Text pl       pl  0.775734\n",
      "56  1000    Text pl       es  0.131588\n",
      "57  1000    Text es       en  0.190045\n",
      "58  1000    Text es       pl  0.190045\n",
      "59  1000    Text es       es  0.703167\n"
     ]
    }
   ],
   "source": [
    "all_texts = {\n",
    "    \"Wiki Long\": long_wiki_counts,\n",
    "    \"Wiki Bad\": bad_wiki_counts,\n",
    "    \"Text en\": en_text_count,\n",
    "    \"Text pl\": pl_text_count,\n",
    "    \"Text es\": es_text_count\n",
    "}\n",
    "\n",
    "languages_data = {\n",
    "    \"en\": eng_lang_top,\n",
    "    \"pl\": pl_lang_top,\n",
    "    \"es\": esp_lang_top\n",
    "}\n",
    "\n",
    "k_values = [3, 10, 100, 1000]\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    for text_name, counts in all_texts.items():\n",
    "        for lang_name, lang_freqs in languages_data.items():\n",
    "            \n",
    "            top_k_freqs = lang_freqs[:k]\n",
    "            \n",
    "            score = lang_confidence_score(counts, top_k_freqs)\n",
    "            \n",
    "            results.append({\n",
    "                \"k\": k,\n",
    "                \"Text\": text_name,\n",
    "                \"Language\": lang_name,\n",
    "                \"Score\": score\n",
    "            })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
